{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import implicit_skill_finder\n","import utils\n","import pandas as pd\n","import numpy as np\n","from joblib import dump, load"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def show_topics(vectorizer, lda_model, n_words=20):\n","    keywords = np.array(vectorizer.get_feature_names())\n","    topic_keywords = []\n","    for topic_weights in lda_model.components_:\n","        top_keyword_locs = (-topic_weights).argsort()[:n_words]\n","        topic_keywords.append(keywords.take(top_keyword_locs))\n","    return topic_keywords"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["text = ['Work on complex and extremely varied data sets from some of the worldâ€™s largest organisations to solve real world problems Develop data science products and solutions for clients as well as for our data science team Write highly optimized code to advance our internal Data Science Toolbox Work in a multi-disciplinary environment with specialists in machine learning, engineering and design Focus on modelling by working alongside the Data Engineering team Add real-world impact to your academic expertise, as you are encouraged to write papers and present at meetings and conferences should you wish Take part in R&D (video: R&D at QuantumBlack); attend conferences such as NIPS and ICML as well as data science retrospectives where you will have the opportunity to share and learn from your co-workers Work in one of the most advanced data science teams globally']\n","doc_ids, docs = implicit_skill_finder.find_similar_texts(text)\n","best_model = load(utils.MODEL_DIR)\n","tf_vectorizer = load(utils.VECTOR_DIR)\n","lda_output = load(utils.OUTPUT_DIR)\n","topic_keywords = show_topics(vectorizer=tf_vectorizer, lda_model=best_model, n_words=15)        \n","df_topic_keywords = pd.DataFrame(topic_keywords)\n","df_topic_keywords.columns = ['Word '+str(i) for i in range(df_topic_keywords.shape[1])]\n","df_topic_keywords.index = ['Topic '+str(i) for i in range(df_topic_keywords.shape[0])]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_document_topic = pd.DataFrame(np.round(lda_output, 2))\n","topic_pos = (-df_document_topic.values).argsort()\n","implicit_skills = set()\n","for i in doc_ids:\n","    for j in range(len(df_topic_keywords)):\n","        if topic_pos[i, j] > 0.3:\n","            implicit_skills.update(df_topic_keywords.iloc[j, :].apply(lambda x: x.strip()).to_list())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(implicit_skills)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":2}
